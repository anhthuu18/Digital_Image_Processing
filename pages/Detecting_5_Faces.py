import streamlit as st
import cv2
import numpy as np
import joblib
from datetime import datetime
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
import os

# Ki·ªÉm tra xem sklearn c√≥ ƒë∆∞·ª£c c√†i ƒë·∫∑t kh√¥ng
try:
    from sklearn.svm import SVC
    from sklearn.preprocessing import LabelEncoder
except ImportError:
    st.error("Th∆∞ vi·ªán 'scikit-learn' ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. H√£y ch·∫°y l·ªánh: pip install scikit-learn")
    raise

# Thi·∫øt l·∫≠p trang
st.set_page_config(
    page_title="Face Recognition",
    layout="wide",
    initial_sidebar_state="expanded"
)

# C·∫•u h√¨nh STUN/TURN servers
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {
            "urls": "turn:openrelay.metered.ca:80",
            "username": "openrelayproject",
            "credential": "openrelayproject",
        }
    ]}
)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u danh s√°ch ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán
if 'upload_recognized' not in st.session_state:
    st.session_state.upload_recognized = set()

class FaceRecognition(VideoProcessorBase):
    def __init__(self):
        # ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n t·ªõi c√°c file
        detector_path = "pages/Source/KhuonMat/face_detection_yunet_2023mar.onnx"
        recognizer_path = "pages/Source/KhuonMat/face_recognition_sface_2021dec.onnx"
        svc_path = "pages/Source/KhuonMat/svc.pkl"
        encoder_path = "pages/Source/KhuonMat/label_encoder.pkl"

        # Ki·ªÉm tra xem c√°c file c√≥ t·ªìn t·∫°i kh√¥ng
        for path in [detector_path, recognizer_path, svc_path, encoder_path]:
            if not os.path.exists(path):
                st.error(f"File kh√¥ng t·ªìn t·∫°i: {path}")
                raise FileNotFoundError(f"File kh√¥ng t·ªìn t·∫°i: {path}")

        # Kh·ªüi t·∫°o m√¥ h√¨nh ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi tham s·ªë ƒëi·ªÅu ch·ªânh
        self.detector = cv2.FaceDetectorYN.create(
            detector_path,
            "",
            (640, 640),
            0.7,  # Gi·∫£m score_threshold ƒë·ªÉ ph√°t hi·ªán d·ªÖ h∆°n
            0.5,  # TƒÉng nms_threshold ƒë·ªÉ tr√°nh b·ªè s√≥t khu√¥n m·∫∑t g·∫ßn nhau
            5000
        )
        self.recognizer = cv2.FaceRecognizerSF.create(
            recognizer_path,
            ""
        )
        self.svc = joblib.load(svc_path)
        self.encoder = joblib.load(encoder_path)

    def process_frame_realtime(self, img):
        height, width = img.shape[:2]
        self.detector.setInputSize((width, height))
        faces = self.detector.detect(img)
        
        # Debug: In s·ªë l∆∞·ª£ng khu√¥n m·∫∑t ph√°t hi·ªán ƒë∆∞·ª£c
        if faces[1] is not None:
            st.write(f"Ph√°t hi·ªán {len(faces[1])} khu√¥n m·∫∑t trong khung h√¨nh realtime")
            face_count = min(len(faces[1]), 5)
            for i in range(face_count):
                try:
                    face = faces[1][i]
                    coords = face[:-1].astype(np.int32)
                    confidence = face[-1]
                    face_align = self.recognizer.alignCrop(img, face)
                    face_feature = self.recognizer.feature(face_align)
                    prediction = self.svc.predict(face_feature.reshape(1, -1))[0]
                    name = self.encoder.inverse_transform([prediction])[0]
                    
                    # V·∫Ω bbox v√† label tr·ª±c ti·∫øp l√™n video
                    cv2.rectangle(img, 
                                (coords[0], coords[1]), 
                                (coords[0]+coords[2], coords[1]+coords[3]), 
                                (0, 255, 0), 2)
                    label = f"{name} ({confidence:.2f})"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(img, 
                                (coords[0], coords[1] - label_size[1] - 10),
                                (coords[0] + label_size[0], coords[1]),
                                (0, 255, 0), -1)
                    cv2.putText(img, label,
                              (coords[0], coords[1] - 5),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                              (0, 0, 0), 2)
                except Exception as e:
                    st.error(f"Error processing face: {str(e)}")
                    continue
        else:
            st.write("Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o trong khung h√¨nh realtime")
        return img

    def process_frame_upload(self, img):
        height, width = img.shape[:2]
        self.detector.setInputSize((width, height))
        faces = self.detector.detect(img)
        
        # Debug: In s·ªë l∆∞·ª£ng khu√¥n m·∫∑t ph√°t hi·ªán ƒë∆∞·ª£c
        if faces[1] is not None:
            st.write(f"Ph√°t hi·ªán {len(faces[1])} khu√¥n m·∫∑t trong ·∫£nh/video upload")
            face_count = min(len(faces[1]), 5)
            for i in range(face_count):
                try:
                    face = faces[1][i]
                    coords = face[:-1].astype(np.int32)
                    confidence = face[-1]
                    face_align = self.recognizer.alignCrop(img, face)
                    face_feature = self.recognizer.feature(face_align)
                    prediction = self.svc.predict(face_feature.reshape(1, -1))[0]
                    name = self.encoder.inverse_transform([prediction])[0]
                    
                    # Th√™m t√™n v√†o danh s√°ch nh·∫≠n di·ªán cho ph·∫ßn upload
                    st.session_state.upload_recognized.add(name)
                    
                    # V·∫Ω bbox v√† label l√™n ·∫£nh/video t·∫£i l√™n
                    cv2.rectangle(img, 
                                (coords[0], coords[1]), 
                                (coords[0]+coords[2], coords[1]+coords[3]), 
                                (0, 255, 0), 2)
                    label = f"{name} ({confidence:.2f})"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(img, 
                                (coords[0], coords[1] - label_size[1] - 10),
                                (coords[0] + label_size[0], coords[1]),
                                (0, 255, 0), -1)
                    cv2.putText(img, label,
                              (coords[0], coords[1] - 5),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                              (0, 0, 0), 2)
                except Exception as e:
                    st.error(f"Error processing face: {str(e)}")
                    continue
        else:
            st.write("Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t n√†o trong ·∫£nh/video upload")
        return img

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        img = self.process_frame_realtime(img)
        return av.VideoFrame.from_ndarray(img, format="bgr24")

def process_uploaded_media(file, media_type):
    processor = FaceRecognition()
    st.session_state.upload_recognized.clear()  # X√≥a danh s√°ch c≈©
    
    if media_type == "image":
        image = np.array(cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR))
        processed_image = processor.process_frame_upload(image)
        return processed_image
    
    elif media_type == "video":
        with open("temp_video.mp4", "wb") as f:
            f.write(file.read())
        cap = cv2.VideoCapture("temp_video.mp4")
        stframe = st.empty()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            processed_frame = processor.process_frame_upload(frame)
            stframe.image(processed_frame, channels="BGR")
        
        cap.release()
        return None

def main():
    st.title("üë• Nh·∫≠n di·ªán khu√¥n m·∫∑t")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Camera Realtime")
        webrtc_ctx = webrtc_streamer(
            key="face-recognition",
            video_processor_factory=FaceRecognition,
            async_processing=True,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={"video": True, "audio": False},
            video_html_attrs={
                "style": {"width": "100%", "margin": "0 auto", "border": "2px solid green"},
                "controls": False,
                "autoPlay": True,
            }
        )

    with col2:
        st.write("### Nh·∫≠n di·ªán t·ª´ Video/H√¨nh ·∫£nh")
        media_type = st.selectbox("Ch·ªçn lo·∫°i media", ["H√¨nh ·∫£nh", "Video"])
        file = st.file_uploader("T·∫£i l√™n file", type=["jpg", "jpeg", "png"] if media_type == "H√¨nh ·∫£nh" else ["mp4"])
        
        if file is not None:
            media_type_lower = "image" if media_type == "H√¨nh ·∫£nh" else "video"
            result = process_uploaded_media(file, media_type_lower)
            if result is not None:
                st.image(result, channels="BGR", caption="K·∫øt qu·∫£ nh·∫≠n di·ªán")
            elif result is None and media_type_lower == "video":
                st.write("Video ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.")
        
        st.write("#### Ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán:")
        if st.session_state.upload_recognized:
            for name in st.session_state.upload_recognized:
                st.write(f"- {name}")
        else:
            st.write("Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ai.")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"Application Error: {str(e)}")