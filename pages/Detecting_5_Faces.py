import streamlit as st
import cv2
import numpy as np
import joblib
from datetime import datetime
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration

# Thi·∫øt l·∫≠p trang
st.set_page_config(
    page_title="Face Recognition",
    layout="wide",
    initial_sidebar_state="expanded"
)

# C·∫•u h√¨nh STUN/TURN servers
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [
        {"urls": ["stun:stun.l.google.com:19302"]},
        {
            "urls": "turn:openrelay.metered.ca:80",
            "username": "openrelayproject",
            "credential": "openrelayproject",
        }
    ]}
)

# Kh·ªüi t·∫°o session state ƒë·ªÉ l∆∞u danh s√°ch ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán cho ph·∫ßn upload
if 'upload_recognized' not in st.session_state:
    st.session_state.upload_recognized = set()

class FaceRecognition(VideoProcessorBase):
    def __init__(self):
        self.detector = cv2.FaceDetectorYN.create(
            "pages/Source/KhuonMat/face_detection_yunet_2023mar.onnx",
            "",
            (640, 640),
            0.7,  # Gi·∫£m ng∆∞·ª°ng tin c·∫≠y ƒë·ªÉ tƒÉng kh·∫£ nƒÉng ph√°t hi·ªán
            0.3,
            5000
        )
        self.recognizer = cv2.FaceRecognizerSF.create(
            "pages/Source/KhuonMat/face_recognition_sface_2021dec.onnx",
            ""
        )
        self.svc = joblib.load('pages/Source/KhuonMat/svc.pkl')
        self.encoder = joblib.load('pages/Source/KhuonMat/label_encoder.pkl')

    def process_frame_realtime(self, img):
        height, width = img.shape[:2]
        self.detector.setInputSize((width, height))
        faces = self.detector.detect(img)
        
        print(f"Realtime - Detected faces: {len(faces[1]) if faces[1] is not None else 0}")
        
        if faces[1] is not None:
            face_count = min(len(faces[1]), 5)
            for i in range(face_count):
                try:
                    face = faces[1][i]
                    coords = face[:-1].astype(np.int32)
                    confidence = face[-1]
                    face_align = self.recognizer.alignCrop(img, face)
                    face_feature = self.recognizer.feature(face_align)
                    prediction = self.svc.predict(face_feature.reshape(1, -1))[0]
                    name = self.encoder.inverse_transform([prediction])[0]
                    
                    # V·∫Ω bbox xung quanh khu√¥n m·∫∑t
                    cv2.rectangle(img, 
                                  (coords[0], coords[1]), 
                                  (coords[0]+coords[2], coords[1]+coords[3]), 
                                  (0, 255, 0),  # M√†u xanh l√°
                                  2)  # ƒê·ªô d√†y vi·ªÅn
                    
                    # V·∫Ω n·ªÅn cho nh√£n
                    label = f"{name} ({confidence:.2f})"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(img, 
                                  (coords[0], coords[1] - label_size[1] - 10),
                                  (coords[0] + label_size[0], coords[1]),
                                  (0, 255, 0),  # M√†u xanh l√°
                                  -1)  # ƒêi·ªÅn k√≠n
                    
                    # V·∫Ω vƒÉn b·∫£n nh√£n
                    cv2.putText(img, label,
                                (coords[0], coords[1] - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                (0, 0, 0),  # M√†u ƒëen
                                2)
                except Exception as e:
                    st.error(f"Error processing face in realtime: {str(e)}")
                    print(f"Error in realtime face processing: {str(e)}")
                    continue
        return img

    def process_frame_upload(self, img):
        height, width = img.shape[:2]
        self.detector.setInputSize((width, height))
        faces = self.detector.detect(img)
        
        print(f"Upload - Detected faces: {len(faces[1]) if faces[1] is not None else 0}")
        
        if faces[1] is not None:
            face_count = min(len(faces[1]), 5)
            for i in range(face_count):
                try:
                    face = faces[1][i]
                    coords = face[:-1].astype(np.int32)
                    confidence = face[-1]
                    face_align = self.recognizer.alignCrop(img, face)
                    face_feature = self.recognizer.feature(face_align)
                    prediction = self.svc.predict(face_feature.reshape(1, -1))[0]
                    name = self.encoder.inverse_transform([prediction])[0]
                    
                    # Th√™m t√™n v√†o danh s√°ch nh·∫≠n di·ªán cho ph·∫ßn upload
                    st.session_state.upload_recognized.add(name)
                    
                    # V·∫Ω bbox xung quanh khu√¥n m·∫∑t
                    cv2.rectangle(img, 
                                  (coords[0], coords[1]), 
                                  (coords[0]+coords[2], coords[1]+coords[3]), 
                                  (0, 255, 0),  # M√†u xanh l√°
                                  2)  # ƒê·ªô d√†y vi·ªÅn
                    
                    # V·∫Ω n·ªÅn cho nh√£n
                    label = f"{name} ({confidence:.2f})"
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
                    cv2.rectangle(img, 
                                  (coords[0], coords[1] - label_size[1] - 10),
                                  (coords[0] + label_size[0], coords[1]),
                                  (0, 255, 0),  # M√†u xanh l√°
                                  -1)  # ƒêi·ªÅn k√≠n
                    
                    # V·∫Ω vƒÉn b·∫£n nh√£n
                    cv2.putText(img, label,
                                (coords[0], coords[1] - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                (0, 0, 0),  # M√†u ƒëen
                                2)
                except Exception as e:
                    st.error(f"Error processing face in upload: {str(e)}")
                    print(f"Error in upload face processing: {str(e)}")
                    continue
        return img

    def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
        img = frame.to_ndarray(format="bgr24")
        img = self.process_frame_realtime(img)
        return av.VideoFrame.from_ndarray(img, format="bgr24")

def process_uploaded_media(file, media_type):
    processor = FaceRecognition()
    st.session_state.upload_recognized.clear()  # X√≥a danh s√°ch c≈©
    
    if media_type == "image":
        image = np.array(cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_COLOR))
        if image is None:
            st.error("Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh. Vui l√≤ng th·ª≠ file kh√°c.")
            return None
        processed_image = processor.process_frame_upload(image)
        return processed_image
    
    elif media_type == "video":
        with open("temp_video.mp4", "wb") as f:
            f.write(file.read())
        cap = cv2.VideoCapture("temp_video.mp4")
        if not cap.isOpened():
            st.error("Kh√¥ng th·ªÉ m·ªü file video. Vui l√≤ng th·ª≠ file kh√°c.")
            return None
        stframe = st.empty()
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            processed_frame = processor.process_frame_upload(frame)
            stframe.image(processed_frame, channels="BGR")
        
        cap.release()
        return None

def main():
    st.title("üë• Nh·∫≠n di·ªán khu√¥n m·∫∑t")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### Camera Realtime")
        webrtc_ctx = webrtc_streamer(
            key="face-recognition",
            video_processor_factory=FaceRecognition,
            async_processing=True,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={"video": True, "audio": False},
            video_html_attrs={
                "style": {"width": "100%", "margin": "0 auto", "border": "2px solid green"},
                "controls": False,
                "autoPlay": True,
            }
        )

    with col2:
        st.write("### Nh·∫≠n di·ªán t·ª´ Video/H√¨nh ·∫£nh")
        media_type = st.selectbox("Ch·ªçn lo·∫°i media", ["H√¨nh ·∫£nh", "Video"])
        file = st.file_uploader("T·∫£i l√™n file", type=["jpg", "jpeg", "png"] if media_type == "H√¨nh ·∫£nh" else ["mp4"])
        
        if file is not None:
            media_type_lower = "image" if media_type == "H√¨nh ·∫£nh" else "video"
            result = process_uploaded_media(file, media_type_lower)
            if result is not None:
                st.image(result, channels="BGR", caption="K·∫øt qu·∫£ nh·∫≠n di·ªán")
            elif result is None and media_type_lower == "video":
                st.write("Video ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.")
        
        st.write("#### Ng∆∞·ªùi ƒë∆∞·ª£c nh·∫≠n di·ªán:")
        if st.session_state.upload_recognized:
            for name in st.session_state.upload_recognized:
                st.write(f"- {name}")
        else:
            st.write("Ch∆∞a nh·∫≠n di·ªán ƒë∆∞·ª£c ai.")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"Application Error: {str(e)}")